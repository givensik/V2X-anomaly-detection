import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
import os
import warnings
warnings.filterwarnings('ignore')

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False

def load_and_validate_data():
    """ë°ì´í„° ë¡œë”© ë° ê¸°ë³¸ ê²€ì¦"""
    print("=== V2X ì „ì²˜ë¦¬ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ===\n")
    
    # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì •
    v2aix_path = 'out/v2aix_preprocessed_fixed.csv'
    veremi_path = 'out/veremi_preprocessed_fixed.csv'
    
    # íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(v2aix_path):
        print(f"âŒ {v2aix_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None, None
    if not os.path.exists(veremi_path):
        print(f"âŒ {veremi_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None, None
    
    # ë°ì´í„° ë¡œë“œ
    print("ğŸ“ ë°ì´í„° ë¡œë”© ì¤‘...")
    v2aix_df = pd.read_csv(v2aix_path)
    veremi_df = pd.read_csv(veremi_path)
    
    # ë°ì´í„°ì…‹ ë¼ë²¨ ì¶”ê°€
    v2aix_df['dataset'] = 'V2AIX'
    veremi_df['dataset'] = 'VeReMi'
    
    print(f"âœ… V2AIX ë°ì´í„°: {len(v2aix_df):,} í–‰, {len(v2aix_df.columns)} ì»¬ëŸ¼")
    print(f"âœ… VeReMi ë°ì´í„°: {len(veremi_df):,} í–‰, {len(veremi_df.columns)} ì»¬ëŸ¼")
    
    return v2aix_df, veremi_df

def analyze_data_quality(v2aix_df, veremi_df):
    """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
    print("\n=== ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ===")
    
    # ê²°ì¸¡ê°’ ë¶„ì„
    print("\nğŸ“Š ê²°ì¸¡ê°’ ë¶„ì„:")
    for name, df in [("V2AIX", v2aix_df), ("VeReMi", veremi_df)]:
        missing_data = df.isnull().sum()
        missing_percent = (missing_data / len(df)) * 100
        missing_info = pd.DataFrame({
            'Missing Count': missing_data,
            'Missing Percent': missing_percent
        }).sort_values('Missing Count', ascending=False)
        
        print(f"\n{name} ê²°ì¸¡ê°’:")
        print(missing_info[missing_info['Missing Count'] > 0])
    
    # ì¤‘ë³µ ë°ì´í„° í™•ì¸
    print(f"\nğŸ”„ ì¤‘ë³µ ë°ì´í„°:")
    print(f"V2AIX ì¤‘ë³µ: {v2aix_df.duplicated().sum():,} í–‰")
    print(f"VeReMi ì¤‘ë³µ: {veremi_df.duplicated().sum():,} í–‰")
    
    # ë°ì´í„° íƒ€ì… í™•ì¸
    print(f"\nğŸ“‹ ë°ì´í„° íƒ€ì…:")
    for name, df in [("V2AIX", v2aix_df), ("VeReMi", veremi_df)]:
        print(f"\n{name} ë°ì´í„° íƒ€ì…:")
        print(df.dtypes.value_counts())

def analyze_label_distribution(v2aix_df, veremi_df):
    """ë¼ë²¨ ë¶„í¬ ë¶„ì„"""
    print("\n=== ë¼ë²¨ ë¶„í¬ ë¶„ì„ ===")
    
    if 'label' not in v2aix_df.columns or 'label' not in veremi_df.columns:
        print("âŒ 'label' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë¼ë²¨ ë¶„í¬ ì‹œê°í™”
    fig, axes = plt.subplots(1, 2, figsize=(15, 6))
    
    for i, (name, df) in enumerate([("V2AIX", v2aix_df), ("VeReMi", veremi_df)]):
        label_counts = df['label'].value_counts()
        attack_ratio = df['label'].mean()
        
        print(f"\n{name}:")
        print(f"  ì •ìƒ: {label_counts.get(0, 0):,} ({1-attack_ratio:.3f})")
        print(f"  ê³µê²©: {label_counts.get(1, 0):,} ({attack_ratio:.3f})")
        
        # íŒŒì´ ì°¨íŠ¸
        axes[i].pie(label_counts.values, labels=['Normal', 'Attack'], autopct='%1.1f%%', startangle=90)
        axes[i].set_title(f'{name} Label Distribution')
    
    plt.tight_layout()
    plt.show()

def analyze_feature_statistics(v2aix_df, veremi_df):
    """í”¼ì²˜ í†µê³„ ë¶„ì„"""
    print("\n=== í”¼ì²˜ í†µê³„ ë¶„ì„ ===")
    
    # ê³µí†µ ì»¬ëŸ¼ ì°¾ê¸°
    common_cols = set(v2aix_df.columns) & set(veremi_df.columns)
    numeric_cols = []
    
    for col in common_cols:
        if col not in ['dataset', 'label'] and v2aix_df[col].dtype in ['int64', 'float64']:
            numeric_cols.append(col)
    
    print(f"ë¶„ì„í•  ìˆ˜ì¹˜í˜• í”¼ì²˜: {len(numeric_cols)}ê°œ")
    
    if len(numeric_cols) == 0:
        print("âŒ ë¶„ì„í•  ìˆ˜ì¹˜í˜• í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í†µê³„ ë¹„êµ í…Œì´ë¸”
    stats_comparison = []
    for col in numeric_cols[:10]:  # ìƒìœ„ 10ê°œë§Œ
        v2aix_stats = v2aix_df[col].describe()
        veremi_stats = veremi_df[col].describe()
        
        stats_comparison.append({
            'Feature': col,
            'V2AIX_Mean': v2aix_stats['mean'],
            'V2AIX_Std': v2aix_stats['std'],
            'VeReMi_Mean': veremi_stats['mean'],
            'VeReMi_Std': veremi_stats['std'],
            'Mean_Diff': abs(v2aix_stats['mean'] - veremi_stats['mean']),
            'Std_Diff': abs(v2aix_stats['std'] - veremi_stats['std'])
        })
    
    stats_df = pd.DataFrame(stats_comparison)
    print("\nğŸ“Š ì£¼ìš” í”¼ì²˜ í†µê³„ ë¹„êµ:")
    print(stats_df.round(4))
    
    return numeric_cols

def visualize_feature_distributions(v2aix_df, veremi_df, numeric_cols):
    """í”¼ì²˜ ë¶„í¬ ì‹œê°í™”"""
    print("\n=== í”¼ì²˜ ë¶„í¬ ì‹œê°í™” ===")
    
    if len(numeric_cols) == 0:
        return
    
    # ë°ì´í„° ê²°í•©
    combined_df = pd.concat([v2aix_df, veremi_df], ignore_index=True)
    
    # ìƒìœ„ 8ê°œ í”¼ì²˜ë§Œ ì‹œê°í™”
    top_features = numeric_cols[:8]
    
    # ë°•ìŠ¤í”Œë¡¯
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes = axes.flatten()
    
    for i, col in enumerate(top_features):
        sns.boxplot(x='dataset', y=col, data=combined_df, ax=axes[i])
        axes[i].set_title(f'{col} Distribution')
        axes[i].tick_params(axis='x', rotation=45)
    
    plt.tight_layout()
    plt.show()
    
    # íˆìŠ¤í† ê·¸ë¨ ë¹„êµ
    fig, axes = plt.subplots(2, 4, figsize=(20, 10))
    axes = axes.flatten()
    
    for i, col in enumerate(top_features):
        v2aix_df[col].hist(alpha=0.7, label='V2AIX', ax=axes[i], bins=30)
        veremi_df[col].hist(alpha=0.7, label='VeReMi', ax=axes[i], bins=30)
        axes[i].set_title(f'{col} Histogram')
        axes[i].legend()
    
    plt.tight_layout()
    plt.show()

def perform_pca_analysis(v2aix_df, veremi_df, numeric_cols):
    """PCA ë¶„ì„"""
    print("\n=== PCA ë¶„ì„ ===")
    
    if len(numeric_cols) < 2:
        print("âŒ PCA ë¶„ì„ì„ ìœ„í•œ ì¶©ë¶„í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ê²°í•©
    combined_df = pd.concat([v2aix_df, veremi_df], ignore_index=True)
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬
    X = combined_df[numeric_cols].fillna(0).values
    X = StandardScaler().fit_transform(X)
    
    # PCA ìˆ˜í–‰
    pca = PCA(n_components=2)
    X_pca = pca.fit_transform(X)
    
    combined_df['pca1'] = X_pca[:, 0]
    combined_df['pca2'] = X_pca[:, 1]
    
    # PCA ì‹œê°í™”
    plt.figure(figsize=(12, 8))
    
    # ìƒ˜í”Œë§ (ë„ˆë¬´ ë§ìœ¼ë©´ ëŠë ¤ì§)
    sample_size = min(5000, len(combined_df))
    sample_df = combined_df.sample(sample_size)
    
    sns.scatterplot(x='pca1', y='pca2', hue='dataset', data=sample_df, alpha=0.6)
    plt.title(f'PCA Analysis - Feature Space Comparison\n(Explained Variance: PC1={pca.explained_variance_ratio_[0]:.3f}, PC2={pca.explained_variance_ratio_[1]:.3f})')
    plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)')
    plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)')
    plt.show()
    
    # í”¼ì²˜ ì¤‘ìš”ë„ (PC1, PC2ì— ëŒ€í•œ ê¸°ì—¬ë„)
    feature_importance = pd.DataFrame({
        'Feature': numeric_cols,
        'PC1_Contribution': np.abs(pca.components_[0]),
        'PC2_Contribution': np.abs(pca.components_[1])
    }).sort_values('PC1_Contribution', ascending=False)
    
    print("\nğŸ“ˆ ì£¼ìš” í”¼ì²˜ì˜ PCA ê¸°ì—¬ë„ (ìƒìœ„ 10ê°œ):")
    print(feature_importance.head(10).round(4))
    
    return pca, feature_importance

def check_data_consistency(v2aix_df, veremi_df):
    """ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬"""
    print("\n=== ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬ ===")
    
    # ê°’ ë²”ìœ„ ê²€ì‚¬
    print("\nğŸ” ê°’ ë²”ìœ„ ê²€ì‚¬:")
    for name, df in [("V2AIX", v2aix_df), ("VeReMi", veremi_df)]:
        print(f"\n{name}:")
        numeric_cols = df.select_dtypes(include=[np.number]).columns
        for col in numeric_cols[:5]:  # ìƒìœ„ 5ê°œë§Œ
            if col not in ['label']:
                min_val = df[col].min()
                max_val = df[col].max()
                print(f"  {col}: [{min_val:.4f}, {max_val:.4f}]")

def generate_quality_report(v2aix_df, veremi_df):
    """í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±"""
    print("\n=== ì „ì²˜ë¦¬ í’ˆì§ˆ ë³´ê³ ì„œ ===")
    
    report = {
        'V2AIX_Rows': len(v2aix_df),
        'V2AIX_Columns': len(v2aix_df.columns),
        'VeReMi_Rows': len(veremi_df),
        'VeReMi_Columns': len(veremi_df.columns),
        'V2AIX_Missing_Total': v2aix_df.isnull().sum().sum(),
        'VeReMi_Missing_Total': veremi_df.isnull().sum().sum(),
        'V2AIX_Duplicates': v2aix_df.duplicated().sum(),
        'VeReMi_Duplicates': veremi_df.duplicated().sum()
    }
    
    if 'label' in v2aix_df.columns and 'label' in veremi_df.columns:
        report['V2AIX_Attack_Ratio'] = v2aix_df['label'].mean()
        report['VeReMi_Attack_Ratio'] = veremi_df['label'].mean()
    
    print("\nğŸ“‹ í’ˆì§ˆ ì§€í‘œ:")
    for key, value in report.items():
        if 'Ratio' in key:
            print(f"  {key}: {value:.3f}")
        else:
            print(f"  {key}: {value:,}")
    
    # í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
    quality_score = 0
    max_score = 100
    
    # ê²°ì¸¡ê°’ ì ìˆ˜ (20ì )
    total_cells = report['V2AIX_Rows'] * report['V2AIX_Columns'] + report['VeReMi_Rows'] * report['VeReMi_Columns']
    missing_ratio = (report['V2AIX_Missing_Total'] + report['VeReMi_Missing_Total']) / total_cells
    quality_score += (1 - missing_ratio) * 20
    
    # ì¤‘ë³µ ë°ì´í„° ì ìˆ˜ (20ì )
    total_rows = report['V2AIX_Rows'] + report['VeReMi_Rows']
    duplicate_ratio = (report['V2AIX_Duplicates'] + report['VeReMi_Duplicates']) / total_rows
    quality_score += (1 - duplicate_ratio) * 20
    
    # ë°ì´í„° í¬ê¸° ì ìˆ˜ (30ì )
    min_rows = min(report['V2AIX_Rows'], report['VeReMi_Rows'])
    if min_rows > 10000:
        quality_score += 30
    elif min_rows > 5000:
        quality_score += 20
    elif min_rows > 1000:
        quality_score += 10
    
    # ë¼ë²¨ ë¶„í¬ ì ìˆ˜ (30ì )
    if 'V2AIX_Attack_Ratio' in report:
        attack_ratios = [report['V2AIX_Attack_Ratio'], report['VeReMi_Attack_Ratio']]
        balanced_score = 1 - abs(attack_ratios[0] - attack_ratios[1])
        quality_score += balanced_score * 30
    
    print(f"\nğŸ¯ ì „ì²˜ë¦¬ í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}/100")
    
    if quality_score >= 80:
        print("âœ… ìš°ìˆ˜í•œ ì „ì²˜ë¦¬ í’ˆì§ˆ")
    elif quality_score >= 60:
        print("âš ï¸ ë³´í†µ ì „ì²˜ë¦¬ í’ˆì§ˆ")
    else:
        print("âŒ ê°œì„ ì´ í•„ìš”í•œ ì „ì²˜ë¦¬ í’ˆì§ˆ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ë°ì´í„° ë¡œë”©
    v2aix_df, veremi_df = load_and_validate_data()
    if v2aix_df is None or veremi_df is None:
        return
    
    # ë°ì´í„° í’ˆì§ˆ ë¶„ì„
    analyze_data_quality(v2aix_df, veremi_df)
    
    # ë¼ë²¨ ë¶„í¬ ë¶„ì„
    analyze_label_distribution(v2aix_df, veremi_df)
    
    # í”¼ì²˜ í†µê³„ ë¶„ì„
    numeric_cols = analyze_feature_statistics(v2aix_df, veremi_df)
    
    # í”¼ì²˜ ë¶„í¬ ì‹œê°í™”
    visualize_feature_distributions(v2aix_df, veremi_df, numeric_cols)
    
    # PCA ë¶„ì„
    perform_pca_analysis(v2aix_df, veremi_df, numeric_cols)
    
    # ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬
    check_data_consistency(v2aix_df, veremi_df)
    
    # í’ˆì§ˆ ë³´ê³ ì„œ ìƒì„±
    generate_quality_report(v2aix_df, veremi_df)
    
    print("\n=== ê²€ì¦ ì™„ë£Œ ===")
    print("ì „ì²˜ë¦¬ëœ ë°ì´í„°ì˜ í’ˆì§ˆì„ ì¢…í•©ì ìœ¼ë¡œ ê²€ì¦í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
