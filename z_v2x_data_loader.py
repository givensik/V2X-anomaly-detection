import json
import os
import pandas as pd
import numpy as np
from pathlib import Path
from typing import Dict, List, Optional

class V2XDataLoader:
    """V2X ë°ì´í„° ë¡œë”© í´ë˜ìŠ¤ - ê°„ë‹¨í•˜ê²Œ ì •ë¦¬

    - V2AIX: ìœ„ë„/ê²½ë„ â†’ ë¯¸í„° ì¢Œí‘œë¡œ ë³€í™˜
    - VeReMi: ì›ë³¸ ë¯¸í„° ì¢Œí‘œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    """
    
    def __init__(self):
        """ë°ì´í„° ë¡œë” ì´ˆê¸°í™”"""
        self.standardize_units = True
        self.ETSI_UNITS = {
            'position': 'meter',
            'speed': 'm/s', 
            'heading': 'degree',
            'timestamp': 'second'
        }
    
    # ---------- V2AIX ë°ì´í„° ë¡œë”© ----------
    def extract_cam_features_v2aix(self, json_data: Dict, scenario_id: str = "") -> List[Dict]:
        """V2AIX ë°ì´í„°ì—ì„œ CAM ë©”ì‹œì§€ íŠ¹ì„± ì¶”ì¶œ"""
        features = []
        if '/v2x/cam' in json_data:
            for cam_msg in json_data['/v2x/cam']:
                try:
                    cam = cam_msg['message']['cam']
                    cam_params = cam['cam_parameters']
                    basic_container = cam_params['basic_container']
                    ref_pos = basic_container['reference_position']

                    hf_container = cam_params['high_frequency_container']
                    if hf_container['choice'] == 0:
                        vehicle_hf = hf_container['basic_vehicle_container_high_frequency']
                        # ETSI CAM í‘œì¤€ì—ì„œ ì‹¤ì œ ë‹¨ìœ„ë¡œ ë³€í™˜
                        lon_deg = ref_pos['longitude']['value'] / 1e7
                        lat_deg = ref_pos['latitude']['value'] / 1e7
                        alt_m = ref_pos['altitude']['altitude_value']['value'] / 100
                        
                        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ì²« ë²ˆì§¸ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¡œì»¬ ë¯¸í„° ì¢Œí‘œë¡œ ë³€í™˜
                        # ì¼ë‹¨ ìœ„ë„/ê²½ë„ë¥¼ ì €ì¥í•˜ê³  ë‚˜ì¤‘ì— ë³€í™˜
                        pos_x = lon_deg  # ê²½ë„ (degree)
                        pos_y = lat_deg  # ìœ„ë„ (degree)
                        
                        feature = {
                            'timestamp': cam_msg['recording_timestamp_nsec'] / 1e9,  # ns â†’ s ë³€í™˜
                            'station_id': cam_msg['message']['header']['station_id']['value'],
                            'pos_x': pos_x,
                            'pos_y': pos_y,
                            'pos_z': alt_m,
                            'heading': vehicle_hf['heading']['heading_value']['value'] / 10,  # degree
                            'speed': vehicle_hf['speed']['speed_value']['value'] / 100,  # m/s
                            'acceleration': vehicle_hf['longitudinal_acceleration']['longitudinal_acceleration_value']['value'] / 10,  # m/sÂ²
                            'curvature': vehicle_hf['curvature']['curvature_value']['value'] / 10000,  # 1/m
                            'spd_x': 0.0, 'spd_y': 0.0, 'spd_z': 0.0,
                            'scenario_id': scenario_id
                        }
                        heading_rad = np.radians(feature['heading'])
                        feature['spd_x'] = feature['speed'] * np.cos(heading_rad)
                        feature['spd_y'] = feature['speed'] * np.sin(heading_rad)
                        features.append(feature)
                except (KeyError, TypeError):
                    continue
        return features

    def load_v2aix_data(self, data_path: str, max_files: int = 10) -> pd.DataFrame:
        """V2AIX ë°ì´í„° ë¡œë”©"""
        all_features = []
        
        # ë‹¨ì¼ íŒŒì¼ì¸ì§€ ë””ë ‰í† ë¦¬ì¸ì§€ í™•ì¸
        if os.path.isfile(data_path):
            json_files = [data_path]
        else:
            json_files = []
            for root, _, files in os.walk(data_path):
                for file in files:
                    if file.endswith('.json') and 'joined' not in file:
                        json_files.append(os.path.join(root, file))
                        if len(json_files) >= max_files:
                            break
                if len(json_files) >= max_files:
                    break

        print(f"V2AIX íŒŒì¼ {len(json_files)}ê°œ ì²˜ë¦¬ ì¤‘...")
        
        for i, file_path in enumerate(json_files):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # íŒŒì¼ ê²½ë¡œë¥¼ ì‹œë‚˜ë¦¬ì˜¤ IDë¡œ ì‚¬ìš©
                scenario_id = file_path.replace('\\', '/').replace(data_path.replace('\\', '/'), '').strip('/')
                features = self.extract_cam_features_v2aix(data, scenario_id)
                all_features.extend(features)
                
                if (i + 1) % 100 == 0:
                    print(f"  ì²˜ë¦¬ ì™„ë£Œ: {i + 1}/{len(json_files)} íŒŒì¼")
                    
            except Exception as e:
                print(f"  íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨: {file_path} - {str(e)}")
                continue

        df = pd.DataFrame(all_features)
        if not df.empty:
            df['dataset'] = 'v2aix'
            df['is_attacker'] = 0  # V2AIXëŠ” ëª¨ë‘ ì •ìƒ ë°ì´í„°
            df['attacker_type'] = 0
            
            # ë¯¸í„° ì¢Œí‘œ ë³€í™˜ ì ìš©
            df = self._convert_v2aix_to_meters(df)
            
        print(f"V2AIX ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(df)} ë ˆì½”ë“œ")
        return df

    def _convert_v2aix_to_meters(self, df: pd.DataFrame) -> pd.DataFrame:
        """V2AIX ìœ„ë„/ê²½ë„ë¥¼ ì‹œë‚˜ë¦¬ì˜¤ë³„ ë¡œì»¬ ë¯¸í„° ì¢Œí‘œë¡œ ë³€í™˜"""
        if df.empty:
            return df
            
        print("V2AIX ì¢Œí‘œë¥¼ ë¯¸í„° ë‹¨ìœ„ë¡œ ë³€í™˜ ì¤‘...")
        
        # ì›ë³¸ ì¢Œí‘œ ë°±ì—…
        df = df.copy()
        df['pos_x_original'] = df['pos_x']  # ê²½ë„
        df['pos_y_original'] = df['pos_y']  # ìœ„ë„
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ì •ë ¬
        df = df.sort_values(['scenario_id', 'station_id', 'timestamp']).reset_index(drop=True)
        
        # ê° ì‹œë‚˜ë¦¬ì˜¤ì˜ ì²« ë²ˆì§¸ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ì ìœ¼ë¡œ ì„¤ì •
        first_positions = df.groupby('scenario_id')[['pos_x', 'pos_y']].first().reset_index()
        first_positions.columns = ['scenario_id', 'first_lon', 'first_lat']
        
        # ê¸°ì¤€ì  ì •ë³´ ë³‘í•©
        df = df.merge(first_positions, on='scenario_id', how='left')
        
        # ì¢Œí‘œ ë³€í™˜ ê³„ìˆ˜
        METERS_PER_DEGREE_LAT = 111320.0  # ìœ„ë„ 1ë„ â‰ˆ 111.32km
        
        # ìœ„ë„/ê²½ë„ ì°¨ì´ ê³„ì‚°
        dlat = df['pos_y'] - df['first_lat']  # ìœ„ë„ ì°¨ì´
        dlon = df['pos_x'] - df['first_lon']  # ê²½ë„ ì°¨ì´
        
        # ê²½ë„ëŠ” ìœ„ë„ì— ë”°ë¼ ë‹¬ë¼ì§ (cos(lat) ì ìš©)
        lat_rad = np.radians(df['first_lat'].clip(-89.999, 89.999))
        meters_per_degree_lon = METERS_PER_DEGREE_LAT * np.cos(lat_rad)
        
        # ë¯¸í„° ë‹¨ìœ„ë¡œ ë³€í™˜
        df['pos_x'] = dlon * meters_per_degree_lon  # X: ë™-ì„œ ë°©í–¥ (ê²½ë„)
        df['pos_y'] = dlat * METERS_PER_DEGREE_LAT  # Y: ë‚¨-ë¶ ë°©í–¥ (ìœ„ë„)
        
        # ì„ì‹œ ì»¬ëŸ¼ ì œê±°
        df = df.drop(['first_lon', 'first_lat'], axis=1)
        
        print(f"V2AIX ì¢Œí‘œ ë³€í™˜ ì™„ë£Œ - ë²”ìœ„: X({df['pos_x'].min():.1f}~{df['pos_x'].max():.1f}m), Y({df['pos_y'].min():.1f}~{df['pos_y'].max():.1f}m)")
        
        return df
    
    # ---------- VeReMi ë°ì´í„° ë¡œë”© ----------
    def extract_cam_features_veremi(self, json_data: List[Dict], ground_truth: List[Dict], scenario_id: str = "") -> List[Dict]:
        """VeReMi ë°ì´í„°ì—ì„œ CAM ë©”ì‹œì§€ íŠ¹ì„± ì¶”ì¶œ (GroundTruthì™€ ë§¤í•‘)"""
        features = []
        attacker_info = {}
        
        # Ground Truthì—ì„œ ê³µê²©ì ì •ë³´ ì¶”ì¶œ
        for gt_entry in ground_truth:
            if gt_entry.get('attackerType', 0) > 0:
                key = (gt_entry['time'], gt_entry['sender'], gt_entry['messageID'])
                attacker_info[key] = gt_entry['attackerType']

        # JSON ë¡œê·¸ì—ì„œ íŠ¹ì„± ì¶”ì¶œ
        for entry in json_data:
            if entry.get('type') == 3:  # CAM ë©”ì‹œì§€ íƒ€ì…
                try:
                    key = (entry['sendTime'], entry['sender'], entry['messageID'])
                    is_attacker = key in attacker_info
                    attacker_type = attacker_info.get(key, 0)
                    
                    # VeReMi ì›ë³¸ ë°ì´í„° (ì‹œë®¬ë ˆì´ì…˜ ë‹¨ìœ„)
                    pos_x_sim = entry['pos'][0]  # ë¯¸í„° (ì‹œë®¬ë ˆì´ì…˜ ì¢Œí‘œ)
                    pos_y_sim = entry['pos'][1]  # ë¯¸í„° (ì‹œë®¬ë ˆì´ì…˜ ì¢Œí‘œ) 
                    pos_z_sim = entry['pos'][2]  # ë¯¸í„°
                    spd_x = entry['spd'][0]      # m/s
                    spd_y = entry['spd'][1]      # m/s
                    spd_z = entry['spd'][2]      # m/s
                    
                    # ì†ë„ì™€ í—¤ë”© ê³„ì‚°
                    speed = float(np.sqrt(spd_x**2 + spd_y**2))  # m/s
                    heading = np.degrees(np.arctan2(spd_y, spd_x))  # degree
                    heading = (heading + 360) % 360  # 0~360ë„ ë²”ìœ„ë¡œ ì¡°ì •
                    # VeReMiëŠ” ë¯¸í„° ë‹¨ìœ„ ì‹œë®¬ë ˆì´ì…˜ ì¢Œí‘œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    pos_x = pos_x_sim  # ë¯¸í„° (ì‹œë®¬ë ˆì´ì…˜ ì¢Œí‘œ)
                    pos_y = pos_y_sim  # ë¯¸í„° (ì‹œë®¬ë ˆì´ì…˜ ì¢Œí‘œ)
                    pos_z = pos_z_sim  # ë¯¸í„°
                    
                    feature = {
                        'timestamp': entry['sendTime'],  # s (ETSI CAMê³¼ ë™ì¼)
                        'station_id': entry['sender'],
                        'pos_x': pos_x,
                        'pos_y': pos_y,
                        'pos_z': pos_z,
                        'spd_x': spd_x,  # m/s (ETSI CAMê³¼ ë™ì¼)
                        'spd_y': spd_y,  # m/s (ETSI CAMê³¼ ë™ì¼)
                        'spd_z': spd_z,  # m/s (ETSI CAMê³¼ ë™ì¼)
                        'heading': heading,  # degree (ETSI CAMê³¼ ë™ì¼)
                        'speed': speed,      # m/s (ETSI CAMê³¼ ë™ì¼)
                        'acceleration': 0.0,  # ì´í›„ ë™ì  í”¼ì²˜ ê³„ì‚°ì—ì„œ ì¬ê³„ì‚°
                        'curvature': 0.0,     # ì´í›„ ë™ì  í”¼ì²˜ ê³„ì‚°ì—ì„œ ì¬ê³„ì‚°
                        'is_attacker': is_attacker,
                        'attacker_type': attacker_type,
                        'scenario_id': scenario_id
                    }
                    features.append(feature)
                except (KeyError, TypeError) as e:
                    continue
                    
        return features

    def load_veremi_data(self, json_log_path: str, ground_truth_path: str, 
                        target_attacker_types: Optional[List[int]] = None) -> pd.DataFrame:
        """VeReMi ë°ì´í„° ë¡œë”© (íŠ¹ì • ê³µê²© íƒ€ì… í•„í„°ë§ ì§€ì›)"""
        try:
            # Ground Truth íŒŒì¼ ì½ê¸°
            ground_truth = []
            with open(ground_truth_path, 'r') as f:
                for line in f:
                    ground_truth.append(json.loads(line.strip()))
            
            # JSON ë¡œê·¸ íŒŒì¼ ì½ê¸°
            json_data = []
            with open(json_log_path, 'r') as f:
                for line in f:
                    json_data.append(json.loads(line.strip()))
            
            # JSON ë¡œê·¸ íŒŒì¼ ê²½ë¡œì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ID ì¶”ì¶œ
            scenario_path = Path(json_log_path)
            current_path = scenario_path.parent  # results
            
            # results ë””ë ‰í† ë¦¬ì—ì„œ ìµœìƒìœ„ ì‹œë‚˜ë¦¬ì˜¤ ë””ë ‰í† ë¦¬ê¹Œì§€ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ê¸°
            while current_path.name not in ['all', 'VeReMi_Data'] and current_path.parent != current_path:
                if current_path.name.startswith('veins_'):  # ì‹œë‚˜ë¦¬ì˜¤ ë””ë ‰í† ë¦¬ íŒ¨í„´
                    scenario_id = current_path.name
                    break
                current_path = current_path.parent
            else:
                scenario_id = scenario_path.parent.name  # ê¸°ë³¸ê°’
                
            # CAM íŠ¹ì„± ì¶”ì¶œ
            features = self.extract_cam_features_veremi(json_data, ground_truth, scenario_id)
            df = pd.DataFrame(features)
            
            # íŠ¹ì • ê³µê²© íƒ€ì… í•„í„°ë§
            if not df.empty and target_attacker_types is not None:
                mask = df['attacker_type'].isin(target_attacker_types)
                df = df[mask].reset_index(drop=True)
                print(f"  ê³µê²© íƒ€ì… {target_attacker_types}ë¡œ í•„í„°ë§: {len(df)} ë ˆì½”ë“œ")
            
            if not df.empty:
                df['dataset'] = 'veremi'

                
                
            return df
            
        except Exception as e:
            print(f"VeReMi ë°ì´í„° ë¡œë”© ì‹¤íŒ¨: {json_log_path} - {str(e)}")
            return pd.DataFrame()

    # ---------- VeReMi ë°ì´í„°ì…‹ ìœ í‹¸ë¦¬í‹° ----------
    def iter_veremi_pairs(self, roots, target_attacker_types=None):
        """VeReMi ë°ì´í„°ì…‹ì—ì„œ (JSONlog, GroundTruth) íŒŒì¼ ìŒì„ ì°¾ëŠ” ì œë„ˆë ˆì´í„°"""
        if isinstance(roots, (str, Path)):
            roots = [roots]

        seen = set()
        for root in map(Path, roots):
            if not root.exists():
                continue
                
            # results í´ë”ë§Œ íƒ€ê²Ÿ (ëŒ€/ì†Œë¬¸ì í˜¼ìš© ì•ˆì „)
            for gt in root.rglob("results/GroundTruthJSONlog.json"):
                # ê³µê²© íƒ€ì… í•„í„°ë§: .sca íŒŒì¼ëª…ìœ¼ë¡œ ë””ë ‰í† ë¦¬ í•„í„°ë§
                if target_attacker_types is not None:
                    sca_files = list(gt.parent.glob("AttackerType*.sca"))
                    if sca_files:
                        # .sca íŒŒì¼ì—ì„œ ê³µê²© íƒ€ì… ì¶”ì¶œ
                        found_types = set()
                        for sca_file in sca_files:
                            # AttackerType2-start=3,0.1-#0.sca -> 2
                            import re
                            match = re.search(r'AttackerType(\d+)-', sca_file.name)
                            if match:
                                found_types.add(int(match.group(1)))
                        
                        # ì›í•˜ëŠ” ê³µê²© íƒ€ì…ì´ ì´ ë””ë ‰í† ë¦¬ì— ì—†ìœ¼ë©´ ìŠ¤í‚µ
                        if not any(att_type in found_types for att_type in target_attacker_types):
                            continue
                    else:
                        # .sca íŒŒì¼ì´ ì—†ëŠ” ë””ë ‰í† ë¦¬ëŠ” ì •ìƒ ì‹œë‚˜ë¦¬ì˜¤ë¡œ ê°„ì£¼
                        if 0 not in target_attacker_types:  # ì •ìƒ ë°ì´í„°ë¥¼ ì›í•˜ì§€ ì•Šìœ¼ë©´ ìŠ¤í‚µ
                            continue
                
                # ê°™ì€ ë””ë ‰í† ë¦¬ì˜ ë¡œê·¸ë“¤
                candidates = list(gt.parent.glob("JSONlog-*.json")) + \
                             list(gt.parent.glob("*JSONlog*.json"))
                             
                for log in candidates:
                    if log.name == "GroundTruthJSONlog.json":
                        continue
                    key = (str(log.resolve()), str(gt.resolve()))
                    if key in seen:
                        continue
                    seen.add(key)
                    yield str(log), str(gt)

    def load_veremi_dataset(self, veremi_root: str, max_files: int = 1000, 
                           directory_filter_types: Optional[List[int]] = None,
                           data_filter_types: Optional[List[int]] = None,
                           max_scenarios: Optional[int] = None) -> pd.DataFrame:
        """VeReMi ë°ì´í„°ì…‹ ì „ì²´ ë¡œë”© (ì—¬ëŸ¬ íŒŒì¼ ì²˜ë¦¬, ì‹œë‚˜ë¦¬ì˜¤ ë””ë ‰í„°ë¦¬ ì œí•œ ì§€ì›)"""
        veremi_dfs = []
            
        print(f"VeReMi ë¡œê·¸ ë¡œë”© ì¤‘ (ìµœëŒ€ {max_files} íŒŒì¼, ìµœëŒ€ {max_scenarios if max_scenarios else 'ì œí•œ ì—†ìŒ'} ì‹œë‚˜ë¦¬ì˜¤)...")
        
        if directory_filter_types:
            print(f"ë””ë ‰í† ë¦¬ í•„í„°ë§: ê³µê²© íƒ€ì… {directory_filter_types}")
        
        all_pairs = list(self.iter_veremi_pairs(veremi_root, target_attacker_types=directory_filter_types))
        print(f"í•„í„°ë§ëœ ë””ë ‰í† ë¦¬ì—ì„œ {len(all_pairs)}ê°œ íŒŒì¼ ìŒ ë°œê²¬")
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ë¡œ ê·¸ë£¹í•‘
        scenario_to_pairs = {}
        for log_path, gt_path in all_pairs:
            # ì‹œë‚˜ë¦¬ì˜¤ ë””ë ‰í† ë¦¬ëª… ì¶”ì¶œ (veins_* ë˜ëŠ” ìƒìœ„ ë””ë ‰í† ë¦¬)
            scenario_dir = Path(log_path).parent
            while not scenario_dir.name.startswith('veins_') and scenario_dir.parent != scenario_dir:
                scenario_dir = scenario_dir.parent
            scenario_id = scenario_dir.name
            scenario_to_pairs.setdefault(scenario_id, []).append((log_path, gt_path))
        
        # ì‹œë‚˜ë¦¬ì˜¤ ì œí•œ ì ìš©
        scenario_ids = list(scenario_to_pairs.keys())
        if max_scenarios is not None:
            scenario_ids = scenario_ids[:max_scenarios]
            print(f"ì‹œë‚˜ë¦¬ì˜¤ ì œí•œ ì ìš©: {len(scenario_ids)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ë§Œ ì‚¬ìš©")
        
        total_files = 0
        for scenario_id in scenario_ids:
            pairs = scenario_to_pairs[scenario_id]
            for log_path, gt_path in pairs:
                if total_files >= max_files:
                    break
                file_name = log_path.split('/')[-1] if '/' in log_path else log_path.split('\\')[-1]
                if (total_files + 1) % 50 == 0:
                    print(f"ì²˜ë¦¬ ì¤‘: {total_files+1}/{min(len(all_pairs), max_files)} - {file_name}")
                df = self.load_veremi_data(log_path, gt_path, data_filter_types)
                if not df.empty:
                    veremi_dfs.append(df)
                total_files += 1
            if total_files >= max_files:
                break
        
        # ëª¨ë“  VeReMi ë°ì´í„° í†µí•©
        veremi_df = pd.concat(veremi_dfs, ignore_index=True) if veremi_dfs else pd.DataFrame()

        # VeReMi ì¤‘ë³µ ë©”ì‹œì§€ ì œê±° (ì „ì²´ ë°ì´í„°ì—ì„œ)
        if not veremi_df.empty:
            print(f"ì¤‘ë³µ ì œê±° ì „: {len(veremi_df)} ë ˆì½”ë“œ")
            # sendTime, sender, scenario_id ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
            veremi_df = veremi_df.drop_duplicates(
                subset=['timestamp', 'station_id', 'scenario_id'], 
                keep='first'
            ).reset_index(drop=True)
            print(f"ì¤‘ë³µ ì œê±° í›„: {len(veremi_df)} ë ˆì½”ë“œ")

            # ì •ë ¬ ì¶”ê°€
            veremi_df = veremi_df.sort_values(
                ['scenario_id', 'station_id', 'timestamp']
            ).reset_index(drop=True)

            # VeReMi ê³µê²© íƒ€ì…ë³„ í†µê³„ ì¶œë ¥
            print("=" * 80)
            print(f"VeReMi ë°ì´í„° ë¡œë”© ì™„ë£Œ: {len(veremi_df)} ë ˆì½”ë“œ")
            attacker_stats = veremi_df['attacker_type'].value_counts().sort_index()
            print("ê³µê²© íƒ€ì…ë³„ ë¶„í¬:")
            for att_type, count in attacker_stats.items():
                att_name = "ì •ìƒ" if att_type == 0 else f"ê³µê²© íƒ€ì… {att_type}"
                print(f"  {att_name}: {count} ë ˆì½”ë“œ ({count/len(veremi_df)*100:.1f}%)")

        return veremi_df

    def analyze_data_quality(self, df: pd.DataFrame, dataset_name: str = "") -> dict:
        """ë°ì´í„° í’ˆì§ˆ ë¶„ì„"""
        quality_report = {
            'dataset_name': dataset_name,
            'rows': len(df),
            'columns': len(df.columns),
            'missing_total': df.isnull().sum().sum(),
            'duplicates': df.duplicated().sum(),
            'numeric_columns': len(df.select_dtypes(include=[np.number]).columns),
            'object_columns': len(df.select_dtypes(include=['object']).columns)
        }
        
        # is_attacker ì»¬ëŸ¼ ë¶„ì„
        if 'is_attacker' in df.columns:
            attack_count = df['is_attacker'].sum()
            quality_report['attack_count'] = int(attack_count)
            quality_report['attack_ratio'] = float(attack_count / len(df)) if len(df) > 0 else 0.0
            quality_report['normal_count'] = int(len(df) - attack_count)
        
        print(f"ğŸ“Š {dataset_name} ë°ì´í„° í’ˆì§ˆ ë¶„ì„:")
        print(f"  - í–‰ ìˆ˜: {quality_report['rows']:,}")
        print(f"  - ì»¬ëŸ¼ ìˆ˜: {quality_report['columns']}")
        print(f"  - ê²°ì¸¡ê°’: {quality_report['missing_total']:,}")
        print(f"  - ì¤‘ë³µ: {quality_report['duplicates']:,}")
        
        if 'attack_count' in quality_report:
            print(f"  - ì •ìƒ: {quality_report['normal_count']:,} ({1-quality_report['attack_ratio']:.1%})")
            print(f"  - ê³µê²©: {quality_report['attack_count']:,} ({quality_report['attack_ratio']:.1%})")
        
        return quality_report

    def get_unit_info(self) -> dict:  
        """í˜„ì¬ ì„¤ì •ëœ ë‹¨ìœ„ ì •ë³´ ë°˜í™˜"""
        return {
            'standardize_units': self.standardize_units,
            'v2aix_units': {
                'position': 'meter (local coordinates)',
                'speed': 'm/s',
                'heading': 'degree',
                'timestamp': 'second (converted from nanosecond)'
            },
            'veremi_units_original': {
                'position': 'meter (simulation coordinates)',
                'speed': 'm/s',
                'heading': 'degree (calculated from velocity)',
                'timestamp': 'second'
            },
            'veremi_units_final': {
                'position': 'meter (simulation coordinates)',
                'speed': 'm/s',
                'heading': 'degree', 
                'timestamp': 'second'
            },
            'coordinate_system': 'meters (unified)',
            'etsi_cam_standard': self.ETSI_UNITS
        }

    def save_standardized_data(self, v2aix_df=None, veremi_df=None):
        """ì´ë¯¸ ë¡œë”©ëœ ë°ì´í„°ë¥¼ z_test ë””ë ‰í† ë¦¬ì— ì €ì¥"""
        print("\n" + "=" * 80)
        print("ë°ì´í„° ì €ì¥ ì¤‘...")
        print("=" * 80)
        
        # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ë¹ˆ DataFrame ìƒì„±
        if v2aix_df is None:
            v2aix_df = pd.DataFrame()
        if veremi_df is None:
            veremi_df = pd.DataFrame()

        # z_test ë””ë ‰í† ë¦¬ ìƒì„± ë° ì €ì¥
        os.makedirs("z_test", exist_ok=True)
        
        # ê°œë³„ ë°ì´í„°ì…‹ ì €ì¥
        if not v2aix_df.empty:
            v2aix_path = "z_test/v2aix_etsi_standardized.csv"
            v2aix_df.to_csv(v2aix_path, index=False)
            print(f"ğŸ’¾ V2AIX ë°ì´í„° ì €ì¥: {v2aix_path}")
        
        if not veremi_df.empty:
            veremi_path = "z_test/veremi_etsi_standardized.csv"
            veremi_df.to_csv(veremi_path, index=False)
            print(f"ğŸ’¾ VeReMi ë°ì´í„° ì €ì¥: {veremi_path}")
        
        # ë‹¨ìœ„ ì •ë³´ë„ ì €ì¥
        unit_info = self.get_unit_info()
        unit_info_path = "z_test/unit_conversion_info.json"
        with open(unit_info_path, 'w', encoding='utf-8') as f:
            json.dump(unit_info, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ë‹¨ìœ„ ë³€í™˜ ì •ë³´ ì €ì¥: {unit_info_path}")
        
        # ìš”ì•½ ì •ë³´ ì €ì¥
        if not v2aix_df.empty or not veremi_df.empty:
            combined_df = pd.concat([v2aix_df, veremi_df], ignore_index=True)
        else:
            combined_df = pd.DataFrame()
            
        total_attackers = len(combined_df[combined_df['is_attacker'] == 1]) if not combined_df.empty else 0
        total_normal = len(combined_df[combined_df['is_attacker'] == 0]) if not combined_df.empty else 0

        summary = {
            'total_records': len(combined_df),
            'v2aix_records': len(v2aix_df) if not v2aix_df.empty else 0,
            'veremi_records': len(veremi_df) if not veremi_df.empty else 0,
            'normal_records': total_normal if not combined_df.empty else 0,
            'attack_records': total_attackers if not combined_df.empty else 0,
            'attack_ratio': total_attackers/(total_normal+total_attackers) if not combined_df.empty and (total_normal+total_attackers) > 0 else 0,
            'columns': list(combined_df.columns) if not combined_df.empty else [],
            'standardization_applied': True,
            'etsi_cam_compliant': True
        }
        
        summary_path = "z_test/data_summary.json"
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ ë°ì´í„° ìš”ì•½ ì •ë³´ ì €ì¥: {summary_path}")

        print("\nâœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: z_test/ ë””ë ‰í† ë¦¬")
        return combined_df if not combined_df.empty else None


def main():
    """ë°ì´í„° ë¡œë”© ì˜ˆì œ"""
    
    # ë°ì´í„° ë¡œë” ì´ˆê¸°í™”
    loader = V2XDataLoader()
    
    # V2AIX ë°ì´í„° ë¡œë”© ì˜ˆì œ
    print("=" * 80)
    print("V2AIX ë°ì´í„° ë¡œë”© ì˜ˆì œ")
    print("=" * 80)
    
    v2aix_path = "V2AIX_Data/json/Mobile/V2X-only"
    v2aix_df = loader.load_v2aix_data(v2aix_path, max_files=10000)
    
    if not v2aix_df.empty:
        loader.analyze_data_quality(v2aix_df, "V2AIX")
    else:
        print("V2AIX ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # VeReMi ë°ì´í„° ë¡œë”© ì˜ˆì œ
    print("\n" + "=" * 80)
    print("VeReMi ë°ì´í„° ë¡œë”© ì˜ˆì œ")
    print("=" * 80)
    
    veremi_root = "VeReMi_Data/all" 
    
    # íŠ¹ì • ê³µê²© íƒ€ì…ë§Œ ë¡œë”©
    print("íŠ¹ì • ê³µê²© íƒ€ì…ë§Œ ë¡œë”© (íƒ€ì… 1, 2):")
    # directory_filter_types: ë””ë ‰í† ë¦¬(ì‹œë‚˜ë¦¬ì˜¤)ì—ì„œ ê³µê²© íƒ€ì… 1, 2ë§Œ í¬í•¨
    # data_filter_types: ì‹¤ì œ ë°ì´í„°ì—ì„œ ì •ìƒ(0), ê³µê²© íƒ€ì… 1, 2ë§Œ í¬í•¨
    veremi_df_filtered = loader.load_veremi_dataset(
        veremi_root=veremi_root,
        max_files=10000,
        directory_filter_types=[0, 8],   # ì‹œë‚˜ë¦¬ì˜¤ ë””ë ‰í† ë¦¬ì—ì„œ ê³µê²© íƒ€ì… 1, 2ë§Œ
        data_filter_types=[0, 8],     # ë°ì´í„°ì—ì„œ ì •ìƒ(0), ê³µê²© 1, 2ë§Œ
        max_scenarios=45               # ì‹œë‚˜ë¦¬ì˜¤ ê°œìˆ˜ ì œí•œ ì—†ìŒ (í•„ìš”ì‹œ ì •ìˆ˜ë¡œ ì œí•œ)
    )
    
    if not veremi_df_filtered.empty:
        loader.analyze_data_quality(veremi_df_filtered, "VeReMi (í•„í„°ë§)")
    
    # í†µí•© ë°ì´í„° ì˜ˆì œ
    print("\n" + "=" * 80)
    print("V2AIX + VeReMi í†µí•© ë°ì´í„°")
    print("=" * 80)
    
    if not v2aix_df.empty and not veremi_df_filtered.empty:
        combined_df = pd.concat([v2aix_df, veremi_df_filtered], ignore_index=True)
        print(f"í†µí•© ë°ì´í„°: {len(combined_df)} ë ˆì½”ë“œ")
        
        # ì „ì²´ ë°ì´í„°ì…‹ì˜ ê³µê²©/ì •ìƒ ë¹„ìœ¨
        total_attackers = len(combined_df[combined_df['is_attacker'] == 1])
        total_normal = len(combined_df[combined_df['is_attacker'] == 0])
        print(f"ì •ìƒ: {total_normal}, ê³µê²©: {total_attackers}")
        if total_attackers > 0:
            print(f"ê³µê²© ë¹„ìœ¨: {total_attackers/(total_normal+total_attackers)*100:.2f}%")
    
    print("\n" + "=" * 80)
    print("ë°ì´í„° ë¡œë”© ì™„ë£Œ!")
    print("=" * 80)
    
    # ë¡œë”©ëœ ë°ì´í„°ë¥¼ ì €ì¥
    loader.save_standardized_data(v2aix_df, veremi_df_filtered)


if __name__ == "__main__":
    main()